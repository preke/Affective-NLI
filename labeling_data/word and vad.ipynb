{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a79a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  labels\n",
       "0  Well, right now I just woke up from a mid-day ...       0\n",
       "1  Well, here we go with the stream of consciousn...       0\n",
       "2  An open keyboard and buttons to push. The thin...       0\n",
       "3  I can't believe it!  It's really happening!  M...       1\n",
       "4  Well, here I go with the good old stream of co...       1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "# df_source = pd.read_csv('../big_5_analysis.tsv', sep='\\t')\n",
    "df_source = pd.read_csv('../../Prompt-Personality/data/Essay/Essay_E_whole.tsv', sep='\\t')\n",
    "df_source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7a2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get vad dict\n",
    "VAD_Lexicons = pd.read_csv('../data/NRC-VAD-Lexicon-Aug2018Release/NRC-VAD-Lexicon.txt', sep='\\t')\n",
    "VAD_dict = {}\n",
    "for r in VAD_Lexicons.iterrows():\n",
    "    VAD_dict[r[1]['Word']] = [r[1]['Valence'], r[1]['Arousal'], r[1]['Dominance']]\n",
    "\n",
    "    \n",
    "def get_VAD_tokenized_dict(i, VAD_dict):\n",
    "    try:\n",
    "        return VAD_dict[i]\n",
    "    except:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e54245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "Positive:\n",
      "0.6265659190190405 0.4453561033523439 0.5219125450904856\n",
      "126587 368323\n",
      "like 5504\n",
      "really 5446\n",
      "think 4139\n",
      "get 3648\n",
      "know 3597\n",
      "time 3206\n",
      "going 3055\n",
      "go 2936\n",
      "would 2908\n",
      "want 2773\n",
      "people 2659\n",
      "one 2494\n",
      "much 2484\n",
      "feel 2241\n",
      "well 2152\n",
      "good 2114\n",
      "right 1964\n",
      "need 1911\n",
      "things 1689\n",
      "school 1682\n",
      "wonder 1613\n",
      "###########################\n",
      "Negative:\n",
      "0.6223603618190102 0.4423219830905501 0.5189131074079172\n",
      "119061 347573\n",
      "like 5064\n",
      "really 4870\n",
      "think 3963\n",
      "know 3400\n",
      "get 3274\n",
      "time 2924\n",
      "want 2750\n",
      "go 2714\n",
      "would 2657\n",
      "going 2640\n",
      "people 2459\n",
      "one 2322\n",
      "much 2254\n",
      "well 2093\n",
      "feel 2021\n",
      "good 2019\n",
      "right 1809\n",
      "need 1711\n",
      "class 1509\n",
      "things 1494\n",
      "school 1475\n",
      "###########################\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "s_list = stopwords.words('english')\n",
    "\n",
    "\n",
    "for personality in ['labels']: #,'cCON','cEXT','cOPN','cNEU']:\n",
    "    print(personality)\n",
    "    print('Positive:')\n",
    "    word_dict = {}\n",
    "    df_a = df_source[df_source[personality] == 1]\n",
    "    v = 0\n",
    "    a = 0\n",
    "    d = 0\n",
    "\n",
    "    oov = 0\n",
    "    total = 0\n",
    "    for uttr in df_a['utterance']:\n",
    "        w_list = re.sub(r'[^\\w\\s\\[\\]]',' ',uttr.lower()).split()\n",
    "        for w in w_list:\n",
    "            if not w in s_list:\n",
    "\n",
    "                total += 1\n",
    "                try:\n",
    "                    v += VAD_dict[w][0]\n",
    "                    a += VAD_dict[w][1]\n",
    "                    d += VAD_dict[w][2]\n",
    "\n",
    "                except:\n",
    "                    oov += 1\n",
    "                try:\n",
    "                    word_dict[w] += 1\n",
    "                except:\n",
    "                    word_dict[w] = 1\n",
    "\n",
    "    match = total-oov\n",
    "    print(v/match,a/match,d/match)\n",
    "    print(oov, total)\n",
    "    \n",
    "    word_dict = {k: v for k, v in sorted(word_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    cnt = 0\n",
    "    for k,v in word_dict.items():\n",
    "        print(k, v)\n",
    "        cnt += 1\n",
    "        if cnt > 20:\n",
    "            break\n",
    "    print('###########################')\n",
    "    print('Negative:')\n",
    "    word_dict = {}\n",
    "    df_a = df_source[df_source[personality] == 0]\n",
    "    v = 0\n",
    "    a = 0\n",
    "    d = 0\n",
    "\n",
    "    oov = 0\n",
    "    total = 0\n",
    "    for uttr in df_a['utterance']:\n",
    "        w_list = re.sub(r'[^\\w\\s\\[\\]]',' ',uttr.lower()).split()\n",
    "        for w in w_list:\n",
    "            if not w in s_list:\n",
    "\n",
    "                total += 1\n",
    "                try:\n",
    "                    v += VAD_dict[w][0]\n",
    "                    a += VAD_dict[w][1]\n",
    "                    d += VAD_dict[w][2]\n",
    "\n",
    "                except:\n",
    "                    oov += 1\n",
    "                try:\n",
    "                    word_dict[w] += 1\n",
    "                except:\n",
    "                    word_dict[w] = 1\n",
    "\n",
    "    match = total-oov\n",
    "    print(v/match,a/match,d/match)\n",
    "    print(oov, total)\n",
    "    \n",
    "    word_dict = {k: v for k, v in sorted(word_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    cnt = 0\n",
    "    for k,v in word_dict.items():\n",
    "        print(k, v)\n",
    "        cnt += 1\n",
    "        if cnt > 20:\n",
    "            break\n",
    "    print('###########################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb9cd009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "{'guy', 'everyone', 'keep', 'hate', 'does', 'person', 'sometimes', 'mom'}\n",
      "{'those', 'your', 'most', 'great', 'best', 'type', 'two', 'read'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_source = pd.read_csv('../../Prompt-Personality/data/Essay/Essay_N_whole.tsv', sep='\\t')\n",
    "df_source.head()\n",
    "\n",
    "pos = \"\"\n",
    "neg = \"\"\n",
    "for doc in df_source[df_source['labels'] == 1]['utterance']:\n",
    "    pos += doc\n",
    "\n",
    "for doc in df_source[df_source['labels'] == 0]['utterance']:\n",
    "    neg += doc\n",
    "\n",
    "    \n",
    "corpus = [pos, neg]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# print(vectorizer.get_feature_names())\n",
    "# print(X.shape)\n",
    "\n",
    "\n",
    "pos_data = { 'word': vectorizer.get_feature_names(),\n",
    "        'tfidf': X.toarray().tolist()[0]}\n",
    "df = pd.DataFrame(pos_data)\n",
    "df = df.sort_values(by=\"tfidf\" , ascending=False) \n",
    "\n",
    "\n",
    "n = 200\n",
    "pos_words = df.head(n)['word']\n",
    "\n",
    "\n",
    "print('************')\n",
    "neg_data = { 'word': vectorizer.get_feature_names(),\n",
    "        'tfidf': X.toarray().tolist()[1]}\n",
    "df = pd.DataFrame(neg_data)\n",
    "df = df.sort_values(by=\"tfidf\" , ascending=False) \n",
    "neg_words = df.head(n)['word']\n",
    "\n",
    "\n",
    "print(set(pos_words) - set(neg_words))\n",
    "print(set(neg_words) - set(pos_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797279e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
